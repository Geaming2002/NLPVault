<h1 align="center">NLPVault</h1>

<div align="center">
    Contributed by 
    <a href="https://github.com/Geaming-CHN">Geaming</a>
</div>


## Table of Contents
<!-- TOC -->

- [Table of Contents](#table-of-contents)
- [Introduction](#introduction)
- [Papers](#papers)
    - [Model](#model)
    - [CoT](#cot)
    - [Retrieval Enhanced LLM](#retrieval-enhanced-llm)
    - [Text Generation](#text-generation)
    - [Agents](#agents)
    - [Benchmark](#benchmark)
    - [Others](#others)
- [Models](#models)
- [Datasets](#datasets)
- [Tools & Libraries](#tools--libraries)
- [Tutorials & Guides](#tutorials--guides)
- [Resources](#resources)
- [Projects](#projects)

<!-- /TOC -->


## Introduction

å‚è€ƒäº†[[Awesome-Story-Generation](https://github.com/yingpengma/Awesome-Story-Generation)]æ‰€æ­å»ºçš„è‡ªå·±çš„NLPèµ„æ–™ä»“åº“ã€‚ä¸»è¦èšç„¦äºNLPçš„LLMåŠå…¶åœ¨å„ä¸ªé¢†åŸŸä¸­çš„åº”ç”¨ã€‚å› ä¸ºæ˜¯ç”±æˆ‘è‡ªå·±æ•´ç†çš„èµ„æ–™ï¼Œå¯èƒ½å­˜åœ¨é”™è¯¯ï¼Œæ¬¢è¿å¤§å®¶éšæ„æPRæˆ–è€…issueã€‚

ä¸æˆ‘è”ç³»ï¼š`jm.li4@siat.ac.cn`

## Papers

***NLPå„ä¸ªé¢†åŸŸè®ºæ–‡é“¾æ¥linkï¼Œåœ¨æ¯ä¸ªé¢†åŸŸä¸­æŒ‰ç…§ä¸»é¢˜ï¼Œå¹´ä»½è¿›è¡Œæ’åºï¼Œâˆšæ˜¯æˆ‘ç”¨æ¥è®°å½•æ˜¯å¦é˜…è¯»çš„ç¬¦å·ï¼Œæ— ç‰¹æ®Šæ„ä¹‰ï¼Œ~è¡¨ç¤ºæ³›è¯»***ğŸ˜

Eg. âˆš`ACL-2023` **Title** [paper] [code] .. [authors]

### Model

- ~`ArXiv-2023` **Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey** [[paper](https://arxiv.org/abs/2311.12351)][[code](https://github.com/Strivin0311/long-llms-learning)][Y Huang, J Xu, Z Jiang, J Laiâ€¦]

- ~`ArXiv-2023` **A survey on long text modeling with transformers** [[paper](https://arxiv.org/abs/2302.14502)][Z Dong, T Tang, L Li, WX Zhao]

### CoT

- `ACL-2023 findings` **Towards reasoning in large language models: A survey** [[paper](https://arxiv.org/abs/2212.10403)][[code](https://github.com/jeffhj/LM-reasoning)][J Huang, KCC Chang]

- âˆš`ACL-2023` **Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions** [[paper](https://arxiv.org/abs/2212.10509)][[code](https://github.com/stonybrooknlp/ircot)][H Trivedi, N Balasubramanian, T Khotâ€¦]

- âˆš`ICLR-2023` **Automatic chain of thought prompting in large language models** [[paper](https://arxiv.org/abs/2210.03493)][[code](https://github.com/amazon-science/auto-cot)][Z Zhang, A Zhang, M Li, A Smola]

- âˆš`NeurIPS-2022` **Chain-of-thought prompting elicits reasoning in large language models** [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html)][J Wei, X Wang, D Schuurmansâ€¦]

### Retrieval Enhanced LLM

- `ArXiv-2023` **Learning to Filter Context for Retrieval-Augmented Generation** [[paper](https://arxiv.org/abs/2311.08377)][[code](https://github.com/zorazrw/filco)][Z Wang, J Araki, Z Jiang, MR Parvezâ€¦]

- âˆš`ArXiv-2023` **Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection** [[paper](https://arxiv.org/abs/2310.11511)][[code](https://selfrag.github.io/)][A Asai, Z Wu, Y Wang, A Sil, H Hajishirzi]

- ~`ArXiv-2023` **A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question Decomposition with Large Language Models** [[paper](https://arxiv.org/abs/2311.07491)][[code](https://github.com/alkaidpku/DQ-ToolQA)][H Cao, Z An, J Feng, K Xu, L Chen, D Zhao]

- ~`ArXiv-2023` **Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models** [[paper](https://arxiv.org/abs/2311.09210)][W Yu, H Zhang, X Pan, K Ma, H Wang, D Yu]

- âˆš`ArXiv-2023` **KNN-LM Does Not Improve Open-ended Text Generation** [[paper](https://arxiv.org/abs/2305.14625)][S Wang, Y Song, A Drozdov, A Garimellaâ€¦]

- âˆš`ArXiv-2023` **Replug: Retrieval-augmented black-box language models** [[paper](https://arxiv.org/abs/2301.12652)][W Shi, S Min, M Yasunaga, M Seo, R Jamesâ€¦]

- âˆš`ArXiv-2023` **Rethinking with retrieval: Faithful large language model inference** [[paper](https://arxiv.org/abs/2301.00303)][[code](https://github.com/HornHehhf/RR)][H He, H Zhang, D Roth]

- âˆš`ICLR-2023` **Generate rather than retrieve: Large language models are strong context generators** [[paper](https://arxiv.org/abs/2209.10063)][[code](https://github.com/wyu97/GenRead)][W Yu, D Iter, S Wang, Y Xu, M Ju, S Sanyalâ€¦]

- `ArXiv-2022` **Atlas: Few-shot learning with retrieval augmented language models** [[paper](https://arxiv.org/abs/2208.03299)][[code](https://github.com/facebookresearch/atlas)][G Izacard, P Lewis, M Lomeli, L Hosseiniâ€¦]

- âˆš`EMNLP-2022` **Training language models with memory augmentation** [[paper](https://arxiv.org/abs/2205.12674)][[code](https://github.com/princeton-nlp/TRIME)][Z Zhong, T Lei, D Chen]

- âˆš`NeurIPS-2021` **End-to-end training of multi-document reader and retriever for open-domain question answering** [[paper](https://proceedings.neurips.cc/paper_files/paper/2021/hash/da3fde159d754a2555eaa198d2d105b2-Abstract.html)][[code](https://github.com/DevSinghSachan/emdr2)][D Singh, S Reddy, W Hamiltonâ€¦]

- âˆš`NeurIPS-2020` **Retrieval-augmented generation for knowledge-intensive nlp tasks** [[paper](https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html)][P Lewis, E Perez, A Piktus, F Petroniâ€¦]

- âˆš`ICLR-2020` **Generalization through memorization: Nearest neighbor language models** [[paper](https://arxiv.org/abs/1911.00172)][U Khandelwal, O Levy, D Jurafskyâ€¦]

- âˆš`ICML-2020` **Retrieval augmented language model pre-training** [[paper](http://proceedings.mlr.press/v119/guu20a.html?ref=https://githubhelp.com)][K Guu, K Lee, Z Tung, P Pasupatâ€¦]

- `ACL-2019` **Latent retrieval for weakly supervised open domain question answering** [[paper](https://arxiv.org/abs/1906.00300)][K Lee, MW Chang, K Toutanova]

### Text Generation

- âˆš`ACL-2023` **STORYWARS: A Dataset and Instruction Tuning Baselines for Collaborative Story Understanding and Generation** [[paper](https://arxiv.org/abs/2305.08152)][[code](https://github.com/ylndu/storywars)][Y Du, L Chilton]

    - P.S. è®ºæ–‡ä¸­é™„çš„ä»£ç ä»“åº“é“¾æ¥å·²ç»404ï¼Œè¯•å›¾å’Œä½œè€…å–å¾—è”ç³»(2023/11/20 15:30)ã€‚

- âˆš`ArXiv-2023` **Retrieval meets Long Context Large Language Models** [[paper](https://arxiv.org/abs/2310.03025)][P Xu, W Ping, X Wu, L McAfee, C Zhu, Z Liuâ€¦]

- âˆš`NeurIPS-2022` **Factuality enhanced language models for open-ended text generation** [[paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/df438caa36714f69277daa92d608dd63-Abstract-Conference.html)][[code](https://github.com/nayeon7lee/FactualityPrompt)][N Lee, W Ping, P Xu, M Patwaryâ€¦]

- âˆš`EMNLP-2022` **Re3: Generating longer stories with recursive reprompting and revision** [[paper](https://arxiv.org/abs/2210.06774)][[code](https://github.com/yangkevin2/emnlp22-re3-story-generation)][K Yang, Y Tian, N Peng, D Klein]

- âˆš`ArXiv-2021` **Automatic story generation: Challenges and attempts** [[paper](https://arxiv.org/abs/2102.12634)][A Alabdulkarim, S Li, X Peng]

- âˆš`AAAI-2019` **Plan-and-write: Towards better automatic storytelling** [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/4726)][[code](https://bitbucket.org/VioletPeng/language-model)][L Yao, N Peng, R Weischedel, K Knightâ€¦]

### Agents

### Benchmark

- âˆš`ACL-2023` **WikiHowQA: A Comprehensive Benchmark for Multi-Document Non-Factoid Question Answering** [[paper](https://aclanthology.org/2023.acl-long.290/)][[code](https://lurunchik.github.io/WikiHowNFQA/)][V Bolotova-Baranova, V Blinovâ€¦]

### Others

- âˆš`ArXiv-2023` **Lost in the middle: How language models use long contexts** [[paper](https://arxiv.org/abs/2307.03172)][NF Liu, K Lin, J Hewitt, A Paranjapeâ€¦]



## Models

***NLPæ¨¡å‹å’Œç®—æ³•***

## Datasets

***å¸¸ç”¨NLPæ•°æ®é›†é“¾æ¥å’Œæè¿°***

## Tools & Libraries

***NLPå·¥å…·å’Œåº“***

## Tutorials & Guides

***NLPå…¥é—¨å’Œé«˜çº§æ•™ç¨‹***

## Resources

***å…¶ä»–èµ„æºï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä¼šè®®è§†é¢‘ã€åšå®¢æ–‡ç« ã€è®²åº§ç¬”è®°ç­‰***

## Projects

***æœ‰è¶£çš„NLPé¡¹ç›®***

